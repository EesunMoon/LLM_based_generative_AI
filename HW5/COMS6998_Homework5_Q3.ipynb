{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_onChxJsw71"
   },
   "source": [
    "# Problem 3\n",
    "Research Questions\n",
    "\n",
    "Instructions: Answer the questions below using only 1–3 simple sentences, followed immediately by the relevant reference (URL, paper title, or patent number).\n",
    "\n",
    "## Assigned Vendor: AssemblyAI (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJJI8siEs9qF"
   },
   "source": [
    "## Part 1: Vendor Profile (2 Points)\n",
    "### 1a. Identify the Vendor & Product: State the specific vendor and the exact model/product name you are researching.\n",
    "\n",
    "- Vendor: AssemblyAI\n",
    "- Product: The primary speech recognition offering is the Universal-2 model, accessed via the AssemblyAI Speech-to-Text API.\n",
    "\n",
    "Reference: https://www.assemblyai.com/docs/getting-started/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdhE_Bu0tBaj"
   },
   "source": [
    "### 1b. Target Use Case & Pricing: What is the primary use case this vendor markets towards? Briefly explain the pricing unit (e.g., “$0.0043 per minute”).\n",
    "\n",
    "AssemblyAI primarily markets its API to developers and enterprises for robust, high-accuracy analysis of audio content, such as call center transcripts, media files, and conversational AI agents. The core transcription model, Universal, uses usage-based pricing starting at $0.15 per hour of pre-recorded audio processed.\n",
    "\n",
    "Reference: https://www.assemblyai.com/pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPxqKUnmtGdH"
   },
   "source": [
    "## Part 2: WER Benchmarking Methodology (10 Base Points + 5 Bonus)\n",
    "Instructions: Choose ANY 2 of the following questions to answer for full base credit (10 Points). Answer the remaining 2 questions for +5 Bonus Points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcJ1fGHztLSe"
   },
   "source": [
    "### 2a. Benchmarking Claim: How does the vendor claim to test their own accuracy? (e.g., “They compare their model against OpenAI Whisper on the Earnings-22 dataset”).\n",
    "AssemblyAI tests its models by comparing their Word Error Rate (WER) against leading commercial and open-source competitors, including Google Speech-to-Text, Amazon Transcribe, and OpenAI Whisper. These comprehensive evaluations span 26+ diverse audio datasets to simulate real-world conditions beyond standard metrics\n",
    "\n",
    "Reference: https://www.assemblyai.com/benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XD_NAzLjtNse"
   },
   "source": [
    "### 2b. Datasets Used: List the specific datasets they cite in their technical blog or papers. (e.g., “LibriSpeech, Common Voice, and proprietary call logs”).\n",
    "\n",
    "They cite the use of well-known public resources like CommonVoice alongside a collection of challenging proprietary, real-world datasets covering various domains, accents, and noisy environments. Their benchmark report methodology is based on over 250 hours of audio data from these 26 datasets.\n",
    "\n",
    "Reference: https://www.assemblyai.com/benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQtHEO1wtPv0"
   },
   "source": [
    "### 2c. Reported WER & Conditions: What is the lowest WER they advertise, and what were the conditions? (e.g., “11.2% WER on noisy audio with background music”).\n",
    "AssemblyAI advertises an overall lowest English WER of 6.6% for their Universal model, achieved across their rigorous, diverse benchmark. On challenging audio conditions like their internal Noisy dataset, their model demonstrated a WER of 10.43%, showing superior robustness compared to competitors.\n",
    "\n",
    "Reference: https://www.assemblyai.com/benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kRdoaVRtYT2"
   },
   "source": [
    "### 2d. Normalization Rules: How do they handle text formatting during scoring? (e.g., “They lowercase all text and remove punctuation before calculating WER”).\n",
    "\n",
    "The company goes beyond standard WER by utilizing U-WER (Unpunctuated WER) and F-WER (Formatted WER) to specifically evaluate the accuracy of text formatting features, including capitalization (Truecasing) and numerical conversions (ITN). This approach ensures that the output is not only accurate in words but also highly readable and usable.\n",
    "\n",
    "Reference: https://www.assemblyai.com/blog/comparing-universal-2-and-openai-whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nuMby6qtaov"
   },
   "source": [
    "## Part 3: The “Secret Sauce” (10 Base Points + 5 Bonus)\n",
    "Instructions: Answer 3a and 3b for full base credit (10 Points). Answer 3c for +5 Bonus Points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9DggzUMtdGe"
   },
   "source": [
    "### 3a. Architecture/Technique (5 Points): What specific technology gives them an advantage? (e.g., “They use a ‘End-to-End Deep Learning’ architecture that skips the traditional phoneme alignment step” or “Groq uses LPU inference chips to speed up Whisper”).\n",
    "\n",
    "AssemblyAI gains an advantage by using a large Conformer RNN-T (Recurrent Neural Network Transducer) architecture with over 600M parameters, which processes speech in an end-to-end manner. This is paired with an innovative All-Neural Text Formatting pipeline that ensures high accuracy in punctuation and casing immediately after transcription.\n",
    "\n",
    "Reference: https://www.assemblyai.com/research/universal-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BGwRELGtfd9"
   },
   "source": [
    "### 3b. Academic Publications (5 Points): Search for and cite 1–3 relevant academic papers where this company’s researchers are primary authors. (Format: Title, Author, Year). If no direct papers exist, find the closest technical whitepaper released by their engineering team.\n",
    "\n",
    "The closest technical whitepaper released by the engineering team details their formatting pipeline, which is key to their model's user-friendliness.\n",
    "\n",
    "Title: Universal-2-TF: Robust All-Neural Text Formatting for ASR Author: (AssemblyAI Team) Year: 2025\n",
    "\n",
    "Reference: https://arxiv.org/html/2501.05948v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Og5jNUPtiSe"
   },
   "source": [
    "### 3c. Patents (Bonus +5 Points): Search for and cite 1–3 relevant patents granted to this company in the last 5 years. (Format: Patent Title, Patent Number). Look specifically for patents related to latency reduction, acoustic modeling, or streaming architecture.\n",
    "\n",
    "No granted patent numbers specifically under the AssemblyAI name related to latency, acoustic modeling, or streaming architecture were identified in the last 5 years. However, their Universal-Streaming product highlights key proprietary innovations in latency reduction, delivering immutable transcripts in ~300ms (P50 latency) for real-time applications.\n",
    "\n",
    "Reference: https://www.assemblyai.com/products/streaming-speech-to-text, https://www.assemblyai.com/blog/introducing-universal-streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oStZ0HkHtk0M"
   },
   "source": [
    "## Part 4: Appendix (3 Points)\n",
    "### 4a. References: Paste a clean, scannable list of all URLs, paper DOIs, and Patent links used to answer the questions above.\n",
    "- [AssemblyAI Documentation](https://www.assemblyai.com/docs/getting-started/models)\n",
    "- [AssemblyAI Pricing Page](https://www.assemblyai.com/pricing)\n",
    "- [AssemblyAI Benchmark Report](https://www.assemblyai.com/benchmarks)\n",
    "- [AssemblyAI Blog (Nov 2024)](https://www.assemblyai.com/blog/comparing-universal-2-and-openai-whisper) – Universal-2 vs Whisper WER comparison\n",
    "- [AssemblyAI Research Report (Oct 2024)](https://www.assemblyai.com/research/universal-2) – Universal-2 improvements, Conformer RNN-T architecture\n",
    "- [ArXiv preprint (2025)](https://arxiv.org/html/2501.05948v1) – “Universal-2-TF: Robust All-Neural Text Formatting for ASR\n",
    "- [AssemblyAI - Universal-Streaming](https://www.assemblyai.com/blog/introducing-universal-streaming)\n",
    "- [AssemblyAI Blog (June 2025)](https://www.assemblyai.com/blog/introducing-universal-streaming) – Universal-Streaming latency (~300ms) and performance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgYyWdECr63O"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
